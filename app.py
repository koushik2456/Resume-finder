import gradio as gr
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from io import BytesIO

# --- Core ML/NLP Libraries ---
# (These are assumed from your previous cells)
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report
from sentence_transformers import SentenceTransformer

# --- 1. Load SBERT Model ---
# (This model must be defined to be used)
try:
Â  Â  # Use 'all-MiniLM-L6-v2' as the default pretrained model
Â  Â  sbert = SentenceTransformer('all-MiniLM-L6-v2') 
Â  Â  print("Pretrained SBERT model loaded.")
except Exception as e:
Â  Â  print(f"Error loading SBERT model: {e}")
Â  Â  # Create a dummy object if loading fails, so app can still load
Â  Â  class DummySBERT:
Â  Â  Â  Â  def encode(self, *args, **kwargs):
Â  Â  Â  Â  Â  Â  print("ERROR: SBERT model not loaded.")
Â  Â  Â  Â  Â  Â  return np.random.rand(kwargs.get('batch_size', 1), 384)
Â  Â  sbert = DummySBERT()

# --- 2. Define Helper Plot Function ---
# (This function was called but not defined in your original cell)
def show_bar(labels, values, title="Top K Matches"):
Â  Â  """Creates a horizontal bar plot and returns the figure."""
Â  Â  plt.style.use('ggplot')
Â  Â  fig, ax = plt.subplots(figsize=(8, max(4, len(labels) * 0.5)))
Â  Â  y_pos = np.arange(len(labels))
Â  Â  ax.barh(y_pos, values, align='center', color='#2b8cbe')
Â  Â  ax.set_yticks(y_pos)
Â  Â  ax.set_yticklabels(reversed(labels)) # Invert to show top match at top
Â  Â  ax.invert_yaxis() 
Â  Â  ax.set_xlabel('Similarity Score')
Â  Â  ax.set_title(title)
Â  Â  ax.set_xlim(0, 1)
Â  Â  
Â  Â  # Add value labels
Â  Â  for i, v in enumerate(reversed(values)):
Â  Â  Â  Â  ax.text(v + 0.01, i, f"{v:.3f}", va='center')
Â  Â  Â  Â  
Â  Â  plt.tight_layout()
Â  Â  return fig

# --- 3. Refactored Retrieval Functions (Fine-tuned removed) ---

def build_indexes_from_uploaded(df_uploaded):
Â  Â  """Builds and returns TF-IDF and SBERT indexes for the uploaded data."""
Â  Â  
Â  Â  # 1) TF-IDF
Â  Â  vect = TfidfVectorizer(max_features=20000, ngram_range=(1,2), stop_words='english')
Â  Â  X = vect.fit_transform(df_uploaded['Resume_str'].astype(str).tolist())
Â  Â  knn_t = NearestNeighbors(n_neighbors=min(50, len(df_uploaded)), metric='cosine', algorithm='brute')
Â  Â  knn_t.fit(X)

Â  Â  # 2) Pretrained SBERT
Â  Â  emb_pre = sbert.encode(df_uploaded['Resume_str'].tolist(), convert_to_numpy=True, show_progress_bar=True)
Â  Â  knn_pre = NearestNeighbors(n_neighbors=min(50, len(df_uploaded)), metric='cosine', algorithm='brute')
Â  Â  knn_pre.fit(emb_pre)

Â  Â  return vect, knn_t, knn_pre

def run_retrieval_for_uploaded(df_uploaded, model_choice, jd, k, vect, knn_t, knn_pre):
Â  Â  """Runs retrieval using the pre-built indexes."""
Â  Â  
Â  Â  if model_choice == 'TF-IDF + KNN':
Â  Â  Â  Â  v = vect.transform([jd])
Â  Â  Â  Â  distances, indices = knn_t.kneighbors(v, n_neighbors=min(k, len(df_uploaded)))
Â  Â  
Â  Â  elif model_choice == 'SBERT (pretrained) + KNN':
Â  Â  Â  Â  vec = sbert.encode([jd], convert_to_numpy=True, show_progress_bar=False)
Â  Â  Â  Â  distances, indices = knn_pre.kneighbors(vec, n_neighbors=min(k, len(df_uploaded)))
Â  Â  
Â  Â  else:
Â  Â  Â  Â  # This case should no longer be reachable
Â  Â  Â  Â  raise ValueError("Invalid model choice.")

Â  Â  sims = 1 - distances[0]
Â  Â  results = df_uploaded.iloc[indices[0]].copy().reset_index().rename(columns={'index':'resume_index'})
Â  Â  results['Similarity'] = sims

Â  Â  # --- Prepare display ---
Â  Â  display_cols = []
Â  Â  if 'ID' in results.columns: display_cols.append('ID')
Â  Â  if 'Name' in results.columns: display_cols.append('Name')
Â  Â  if 'Category' in results.columns: display_cols.append('Category')
Â  Â  display_cols.append('Similarity')
Â  Â  
Â  Â  # Ensure all display_cols exist, add if missing
Â  Â  for col in display_cols:
Â  Â  Â  Â  if col not in results.columns:
Â  Â  Â  Â  Â  Â  results[col] = 'N/A'
Â  Â  Â  Â  Â  Â  
Â  Â  display = results[display_cols].head(k)

Â  Â  # --- Build plot ---
Â  Â  labels = results['Name'].tolist() if 'Name' in results.columns else results['resume_index'].astype(str).tolist()
Â  Â  fig = show_bar(labels[:k], results['Similarity'].tolist()[:k], title=f"Top {k} matches ({model_choice})")

Â  Â  # --- Prepare CSV download bytes ---
Â  Â  csv_bytes = display.to_csv(index=False).encode()
Â  Â  
Â  Â  return display, fig, csv_bytes

# --- 4. Main Gradio App Function ---

def run_app(uploaded_file, model_choice, jd, k, compute_metrics, true_label):
Â  Â  """
Â  Â  Main function triggered by the 'Run' button.
Â  Â  Reads the file, builds indexes, runs retrieval, and computes metrics.
Â  Â  """
Â  Â  if uploaded_file is None:
Â  Â  Â  Â  return pd.DataFrame(), None, None, "ğŸš« Error: Please upload a CSV file first."
Â  Â  if not jd or not jd.strip():
Â  Â  Â  Â  return pd.DataFrame(), None, None, "ğŸš« Error: Please enter a Job Description."
Â  Â  Â  Â  
Â  Â  # --- Read and normalize CSV ---
Â  Â  try:
Â  Â  Â  Â  df_u = pd.read_csv(uploaded_file.name, engine='python')
Â  Â  except Exception as e:
Â  Â  Â  Â  return pd.DataFrame(), None, None, f"ğŸš« Error reading CSV: {e}"

Â  Â  # Normalize columns
Â  Â  cols = [c.strip() for c in df_u.columns]
Â  Â  col_map = {}
Â  Â  
Â  Â  # Find Resume column
Â  Â  resume_col = next((c for c in cols if any(tok in c.lower() for tok in ['resume','cv','text','profile','description','content','summary'])), None)
Â  Â  if resume_col is None:
Â  Â  Â  Â  return pd.DataFrame(), None, None, "ğŸš« Error: Couldn't find a resume column (e.g., 'Resume_str', 'text')."
Â  Â  col_map[resume_col] = 'Resume_str'
Â  Â  
Â  Â  # Find optional columns
Â  Â  if 'Name' not in cols:
Â  Â  Â  Â  col_map[next((c for c in cols if 'name' in c.lower()), 'Name')] = 'Name'
Â  Â  if 'ID' not in cols:
Â  Â  Â  Â  col_map[next((c for c in cols if 'id' in c.lower()), 'ID')] = 'ID'
Â  Â  if 'Category' not in cols:
Â  Â  Â  Â  col_map[next((c for c in cols if any(tok in c.lower() for tok in ['category','role','position','dept'])), 'Category')] = 'Category'

Â  Â  df_u = df_u.rename(columns=col_map)
Â  Â  
Â  Â  # Add placeholders if still missing
Â  Â  if 'Name' not in df_u.columns: df_u['Name'] = "(Not Provided)"
Â  Â  if 'ID' not in df_u.columns: df_u['ID'] = df_u.index
Â  Â  if 'Category' not in df_u.columns: df_u['Category'] = "Unknown"

Â  Â  df_u = df_u.dropna(subset=['Resume_str']).reset_index(drop=True)
Â  Â  if df_u.empty:
Â  Â  Â  Â  return pd.DataFrame(), None, None, "ğŸš« Error: No valid resume data found after loading."

Â  Â  # --- Build indexes (This is the slow part) ---
Â  Â  try:
Â  Â  Â  Â  vect, knn_t, knn_pre = build_indexes_from_uploaded(df_u)
Â  Â  except Exception as e:
Â  Â  Â  Â  return pd.DataFrame(), None, None, f"ğŸš« Error building indexes: {e}"

Â  Â  # --- Run retrieval ---
Â  Â  display, fig, csv_bytes = run_retrieval_for_uploaded(df_u, model_choice, jd, k, vect, knn_t, knn_pre)

Â  Â  # --- Optionally compute metrics ---
Â  Â  metrics_text = "Metrics not computed (checkbox not selected or 'Category' column missing)."
Â  Â  if compute_metrics:
Â  Â  Â  Â  # Determine true label
Â  Â  Â  Â  if true_label and str(true_label).strip():
Â  Â  Â  Â  Â  Â  tlabel = str(true_label).strip()
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # Simple auto-detect (can be improved)
Â  Â  Â  Â  Â  Â  all_cats = [str(c) for c in df_u['Category'].unique()]
Â  Â  Â  Â  Â  Â  jd_low = jd.lower()
Â  Â  Â  Â  Â  Â  tlabel = next((c for c in all_cats if c.lower() in jd_low), "Unknown")
Â  Â  Â  Â  Â  Â  if tlabel == "Unknown":
Â  Â  Â  Â  Â  Â  Â  Â  tlabel = df_u['Category'].mode().iloc[0]

Â  Â  Â  Â  y_true = [tlabel] * len(display)
Â  Â  Â  Â  y_pred = display['Category'].astype(str).tolist()
Â  Â  Â  Â  
Â  Â  Â  Â  p = precision_score(y_true, y_pred, average='micro', zero_division=0)
Â  Â  Â  Â  r = recall_score(y_true, y_pred, average='micro', zero_division=0)
Â  Â  Â  Â  f = f1_score(y_true, y_pred, average='micro', zero_division=0)
Â  Â  Â  Â  cls_report = classification_report(y_true, y_pred, zero_division=0, labels=np.unique(y_true + y_pred))
Â  Â  Â  Â  
Â  Â  Â  Â  metrics_text = (f"ğŸ“ˆ Metrics (Top-K Results vs. True Label)\n"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"----------------------------------------\n"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"True Label Used: {tlabel}\n"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"Micro-Precision: {p:.3f}\n"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"Micro-Recall: Â  Â {r:.3f}\n"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"Micro-F1-Score: Â {f:.3f}\n\n"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"Classification Report (Top-K):\n{cls_report}")

Â  Â  # --- Prepare CSV for download ---
Â  Â  tmp = None
Â  Â  if csv_bytes is not None:
Â  Â  Â  Â  tmp = BytesIO(csv_bytes)
Â  Â  Â  Â  # This name is important for the download
Â  Â  Â  Â  tmp.name = "top_k_results.csv" 

Â  Â  return display, fig, tmp, metrics_text
# --- 5. Gradio UI (Aesthetic & Fine-tuned removed) ---
# (The functions like run_app, build_indexes_from_uploaded, etc. are all correct)
# (Paste this code to replace your existing gr.Blocks section)

with gr.Blocks(theme=gr.themes.Soft(primary_hue="blue", secondary_hue="orange")) as demo_app:
Â  Â  gr.Markdown(
Â  Â  Â  Â  """
Â  Â  Â  Â  # ğŸš€ Smart Resume Finder ğŸš€
Â  Â  Â  Â  Upload your resume CSV, paste a job description, and find the best matches!
Â  Â  Â  Â  
Â  Â  Â  Â  **Instructions:**
Â  Â  Â  Â  1. Â Upload a CSV file containing your resumes. Must have a text column (e.g., 'Resume_str') and ideally 'Name' and 'Category'.
Â  Â  Â  Â  2. Â Select the matching model (TF-IDF for speed, SBERT for better accuracy).
Â  Â  Â  Â  3. Â Paste the job description.
Â  Â  Â  Â  4. Â Click 'Find Matches'.
Â  Â  Â  Â  """
Â  Â  )
Â  Â  
Â  Â  # --- FIX 1: Add an invisible State component to reliably hold the file data ---
Â  Â  download_state = gr.State(value=None)
Â  Â  
Â  Â  # Use tabs for a clean layout
Â  Â  with gr.Tabs():
Â  Â  Â  Â  
Â  Â  Â  Â  # --- TAB 1: Setup & Run ---
Â  Â  Â  Â  with gr.TabItem("1. Setup & Run"):
Â  Â  Â  Â  Â  Â  with gr.Row():
Â  Â  Â  Â  Â  Â  Â  Â  with gr.Column(scale=1):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  upload = gr.File(label="Upload Resume CSV", file_types=[".csv"])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model_choice = gr.Radio(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  choices=['TF-IDF + KNN', 'SBERT (pretrained) + KNN'],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value='SBERT (pretrained) + KNN', 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="ğŸ¤– Choose Retrieval Model"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  with gr.Column(scale=2):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  jd_txt = gr.Textbox(lines=10, label="ğŸ“‹ Paste Job Description Here")

Â  Â  Â  Â  Â  Â  with gr.Accordion("âš™ï¸ Advanced Options (Metrics & Top-K)", open=False):
Â  Â  Â  Â  Â  Â  Â  Â  k_slider = gr.Slider(1, 20, value=5, step=1, label="K (Number of results)")
Â  Â  Â  Â  Â  Â  Â  Â  compute_metrics = gr.Checkbox(label="Compute Metrics (requires 'Category' column)", value=False)
Â  Â  Â  Â  Â  Â  Â  Â  true_label_text = gr.Textbox(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="True Label (Optional: for metrics)", 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  placeholder="e.g., HR (if blank, will try to auto-detect)"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  run_btn = gr.Button("ğŸš€ Find Matches", variant="primary")

Â  Â  Â  Â  # --- TAB 2: Results ---
Â  Â  Â  Â  with gr.TabItem("2. View Results"):
Â  Â  Â  Â  Â  Â  with gr.Row():
Â  Â  Â  Â  Â  Â  Â  Â  result_table = gr.Dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  headers=['ID', 'Name', 'Category', 'Similarity'], 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="ğŸ† Top Matches"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  result_plot = gr.Plot(label="ğŸ“Š Similarity Plot")
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  info_out = gr.Textbox(label="â„¹ï¸ Info / Metrics Log", lines=10, interactive=False)
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  download_btn = gr.Button("ğŸ’¾ Download Top-K CSV")

Â  Â  # --- Button Click Logic ---
Â  Â  
Â  Â  # 1. Main run button
Â  Â  run_btn.click(
Â  Â  Â  Â  fn=run_app, 
Â  Â  Â  Â  inputs=[upload, model_choice, jd_txt, k_slider, compute_metrics, true_label_text],
Â  Â  Â  Â  
Â  Â  Â  Â  # --- FIX 2: Output the file object (tmp) to download_state, NOT download_btn ---
Â  Â  Â  Â  outputs=[result_table, result_plot, download_state, info_out]
Â  Â  )

Â  Â  # 2. Download button logic
Â  Â  def download_results(tmpfile_from_state):
Â  Â  Â  Â  if tmpfile_from_state is None:
Â  Â  Â  Â  Â  Â  print("No file to download.")
Â  Â  Â  Â  Â  Â  # You can raise an error to show the user
Â  Â  Â  Â  Â  Â  gr.Warning("No file to download! Click 'Find Matches' first.")
Â  Â  Â  Â  Â  Â  return None
Â  Â  Â  Â  return tmpfile_from_state

Â  Â  download_btn.click(
Â  Â  Â  Â  fn=download_results, 
Â  Â  Â  Â  # --- FIX 3: Get the file data from download_state, NOT download_btn ---
Â  Â  Â  Â  inputs=[download_state], 
Â  Â  Â  Â  outputs=[gr.File(label="Download CSV")]
Â  Â  )

# --- Launch the App ---
# (share=True prints the shareable public URL)
demo_app.launch()
